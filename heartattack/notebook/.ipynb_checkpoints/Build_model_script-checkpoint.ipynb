{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Python\\\\pluralsight\\\\datascience-learning\\\\heartattack\\\\models\\\\knn_model.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.path.pardir,\"models\",\"knn_model.py\")\n",
    "functions_path = os.path.join(os.path.pardir,\"models\",\"model_functions.py\")\n",
    "init_path = os.path.join(os.path.pardir,\"models\",\"__init__.py\")\n",
    "pardir_init_path = os.path.join(os.path.pardir,\"__init__.py\")\n",
    "os.path.abspath(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\models\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $init_path\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $pardir_init_path\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\models\\model_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $functions_path\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def check_size_prep_test(predict_raw_data_path):\n",
    "    predict_df = pd.read_csv(predict_raw_data_path)\n",
    "    if len(predict_df) < 100:\n",
    "        raw_data_path = os.path.join(os.path.pardir,\"data\",\"raw\", \"heart_failure_clinical_records_dataset.csv\")\n",
    "        raw_df = pd.read_csv(raw_data_path)\n",
    "        predict_df = pd.concat([raw_df,predict_df],axis=0)\n",
    "    return predict_df\n",
    "        \n",
    "    \n",
    "def identify_model_features(df):\n",
    "    model_features = df.columns.drop('DEATH_EVENT')\n",
    "    model_target = 'DEATH_EVENT'\n",
    "    numerical_features_all = df[model_features].select_dtypes(include=np.number).columns\n",
    "    categorical_features_all = df[model_features].select_dtypes(include='object').columns\n",
    "    return numerical_features_all,categorical_features_all,model_target\n",
    "\n",
    "def drop_outliers(df,numerical_features_all):\n",
    "    for c in numerical_features_all:\n",
    "        Q1 = df[c].quantile(0.25)\n",
    "        Q3 = df[c].quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "        dropIndexes = df[df[c] < Q1-1.5*IQR].index\n",
    "        if len(dropIndexes) > 0:\n",
    "            df.drop(dropIndexes,inplace=True)\n",
    "        dropIndexes = df[df[c] > Q3+1.5*IQR].index\n",
    "        if len(dropIndexes) > 0:\n",
    "            df.drop(dropIndexes,inplace=True)\n",
    "    return df\n",
    "\n",
    "def impute_numerical_features(df,numerical_features_all,numerical_imputed_json_path):\n",
    "    df_imputed = df.copy()\n",
    "    df_imputed[numerical_features_all] = df_imputed[numerical_features_all].fillna(df_imputed[numerical_features_all].mean())\n",
    "    #store imputataion value in json\n",
    "    numerical_imputation_json = df_imputed[numerical_features_all].mean().to_json(orient=\"index\")\n",
    "    with open(numerical_imputed_json_path,\"w\") as jsonfile:\n",
    "        jsonfile.write(numerical_imputation_json)\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "def impute_categorical_features(df_imputed,categorical_features_all,categorical_imputed_json_path):\n",
    "    mode_dict = dict()\n",
    "    #identify the mode\n",
    "    for c in df_imputed[categorical_features_all]:\n",
    "        mode_value = df_imputed[c].mode()\n",
    "        mode_dict[c] = mode_value\n",
    "\n",
    "        #impute feature with mode\n",
    "        df_imputed[c].fillna(mode_value,inplace=True)\n",
    "    #store ctegorical mode values in json\n",
    "    categorical_imputation_json = json.dumps(mode_dict)\n",
    "    with open(categorical_imputed_json_path,\"w\") as jsonfile:\n",
    "        jsonfile.write(categorical_imputation_json)\n",
    "    return df_imputed\n",
    "\n",
    "def feature_encoding(df,model_target):\n",
    "    df = df.drop(columns=[\"time\"])\n",
    "    \n",
    "    df = df.astype({\"age\":\"int8\"})\n",
    "    #cut equal size bins for age with actual frequency..use qcut where unequal bins but distribution of value\n",
    "\n",
    "    age_bins=[0,5,15,30,45,60,75,90,105]\n",
    "    age_labels = [\"kid\",\"teen\",\"young\",\"midage\",\"upperage\",\"senior\",\"old\",\"veryold\"]\n",
    "    df[\"age\"] = pd.cut(df[\"age\"],bins=age_bins,labels=age_labels)\n",
    "    qcut_labels = [\"verylow\",\"low\",\"med\",\"high\",\"veryhigh\"] \n",
    "    df[\"creatinine_phosphokinase\"] = pd.qcut(df[\"creatinine_phosphokinase\"],q=5,labels=qcut_labels)\n",
    "    #df[\"ejection_fraction\"] = pd.qcut(df[\"ejection_fraction\"]),q=5,lables=qcut_labels)\n",
    "    df[\"platelets\"] = pd.qcut(df[\"platelets\"],q=5,labels=qcut_labels)\n",
    "    df[\"serum_creatinine\"]=pd.qcut(df[\"serum_creatinine\"],q=5,labels=qcut_labels)\n",
    "    #df[\"serum_sodium\"] = pd.qcut(df[\"serum_sodium\"],q=5,labels=qcut_labels)\n",
    "    #df[\"time\"] = pd.qcut(df[\"time\"],q=5,labels=qcut_labels)\n",
    "    df_encoded = pd.get_dummies(df)\n",
    "    #move target column to the end of df\n",
    "    target = df_encoded[model_target]\n",
    "    df_encoded.drop(columns=[model_target], inplace=True)\n",
    "    df_encoded.insert(30,model_target,target)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ..\\models\\knn_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_path\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score,accuracy_score\n",
    "from model_functions import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raw_data_path = os.path.join(os.path.pardir,\"data\",\"raw\", \"heart_failure_clinical_records_dataset.csv\")\n",
    "    prediction_path = os.path.join(os.path.pardir,\"data\",\"predictions\", \"prediction.csv\")\n",
    "    trained_model_path = os.path.join(os.path.pardir,\"models\",\"knn_model.pickle\")\n",
    "    numerical_imputed_json_path = os.path.join(os.path.pardir,\"static_data\",\"numeric_imputed_values.json\")\n",
    "    categorical_imputed_json_path = os.path.join(os.path.pardir,\"static_data\",\"categorical_imputed_values.json\")\n",
    "    \n",
    "    try:\n",
    "        dataset = sys.argv[-1]\n",
    "        test_dataset_path = os.path.join(os.path.pardir,\"data\",\"raw\", dataset)    \n",
    "    except:\n",
    "        pass\n",
    "    print(\"Exception orrcured...using sample datatset\")\n",
    "        #raw_data_path = os.path.join(os.path.pardir,\"data\",\"raw\", \"heart_failure_clinical_records_dataset.csv\")\n",
    "        \n",
    "    df = pd.read_csv(raw_data_path)\n",
    "    #separating feature and target  \n",
    "    numerical_features_all, categorical_features_all, model_target = identify_model_features(df)\n",
    "    #removing outliers\n",
    "    df = drop_outliers(df,numerical_features_all)\n",
    "    #Impute numerical feature missing with mean value\n",
    "    df_imputed = impute_numerical_features(df,numerical_features_all,numerical_imputed_json_path)\n",
    "\n",
    "    #Impute categorical feature missing with Mode (most frequent) value\n",
    "    df_imputed = impute_categorical_features(df_imputed,categorical_features_all,categorical_imputed_json_path)\n",
    "    #Feature encoding\n",
    "    df_encoded = feature_encoding(df_imputed,model_target)\n",
    "\n",
    "    train_data, test_data = train_test_split(df_encoded,test_size=0.1,shuffle=True,random_state=23)\n",
    "    class_0 = train_data[train_data[model_target] == 0 ]\n",
    "    class_1 = train_data[train_data[model_target] == 1 ]\n",
    "\n",
    "    sampled_class_1 = class_1.sample(n=len(class_0),replace=True,random_state=42)\n",
    "\n",
    "    train_data = pd.concat([sampled_class_1,class_0])\n",
    "    train_data = shuffle(train_data)\n",
    "    #use pipeline classsifier\n",
    "    final_model_features = train_data.iloc[0:1,0:30].columns\n",
    "    X_train = train_data[final_model_features]\n",
    "    y_train = train_data[model_target]\n",
    "\n",
    "    X_test = test_data[final_model_features]\n",
    "    y_test = test_data[model_target]\n",
    "    \n",
    "    classifier = Pipeline([('imputer',SimpleImputer(strategy='mean')),\n",
    "                            ('estimator',KNeighborsClassifier(n_neighbors=8,metric=\"manhattan\"))   \n",
    "                        ])\n",
    "    \n",
    "    knn_clf = classifier.fit(X_train,y_train)\n",
    "    \n",
    "    #predict\n",
    "    train_prediction = classifier.predict(X_train)\n",
    "    #Model perforfance and report for Train data\n",
    "    print(\"Model perforfance for Train data\", confusion_matrix(y_train,train_prediction),end=\"\\n\")\n",
    "    print(classification_report(y_train,train_prediction),end=\"\\n\")\n",
    "    print(\"Model accuracy train data: \",accuracy_score(y_train,train_prediction),end=\"\\n\")\n",
    "    \n",
    "    #Model performance for Test data\n",
    "    X_test = test_data[final_model_features]\n",
    "    y_test=test_data[model_target]\n",
    "    test_prediction = classifier.predict(X_test)\n",
    "\n",
    "    print(\"Model perforfance \", confusion_matrix(y_test,test_prediction),end=\"\\n\")\n",
    "    print(classification_report(y_test,test_prediction),end=\"\\n\")\n",
    "    print(\"Model accuracy: \",accuracy_score(y_test,test_prediction),end=\"\\n\")\n",
    "    #pd.concat([test_data.reset_index(),pd.DataFrame(test_prediction).reset_index()],axis=1).to_csv(prediction_path,header=True,index=False)\n",
    "    #save trained model\n",
    "    with open(trained_model_path, \"wb\") as trained_pkl_file:\n",
    "        pickle.dump(knn_clf,trained_pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception orrcured...using sample datatset\n",
      "Model perforfance for Train data [[119  27]\n",
      " [ 28 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       146\n",
      "           1       0.81      0.81      0.81       146\n",
      "\n",
      "    accuracy                           0.81       292\n",
      "   macro avg       0.81      0.81      0.81       292\n",
      "weighted avg       0.81      0.81      0.81       292\n",
      "\n",
      "Model accuracy train data:  0.8116438356164384\n",
      "Model perforfance  [[12  6]\n",
      " [ 2  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75        18\n",
      "           1       0.33      0.60      0.43         5\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.60      0.63      0.59        23\n",
      "weighted avg       0.74      0.65      0.68        23\n",
      "\n",
      "Model accuracy:  0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "!python $model_path heart_failure_clinical_records_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
